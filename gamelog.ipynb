{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ids = [\n",
    "    \"j/jamesle01\", \"c/curryst01\", \"d/duranke01\", \"a/antetgi01\", \"d/doncilu01\",\n",
    "    \"j/jokicni01\", \"e/embiijo01\", \"t/tatumja01\", \"b/butleji01\", \"l/leonaka01\",\n",
    "    \"l/lillada01\", \"h/hardeja01\", \"d/davisan02\", \"b/bookede01\", \"m/mitchdo01\",\n",
    "    \"w/willizi01\", \"m/moranja01\", \"y/youngtr01\", \"t/townska01\", \"b/bealbr01\",\n",
    "    \"g/georgpa01\", \"i/irvinky01\", \"p/paulch01\", \"d/derozde01\", \"w/westbru01\",\n",
    "    \"a/adebaba01\", \"h/holidjr01\", \"m/middlkh01\", \"s/siakapa01\", \"v/vanvlfr01\",\n",
    "    \"g/gilgesh01\", \"i/ingrabr01\", \"m/mccolcj01\", \"b/ballla01\", \"h/halibty01\",\n",
    "    \"r/randlju01\", \"b/barrerj01\", \"f/foxde01\", \"s/sabondo01\", \"t/turnemy01\",\n",
    "    \"p/portemi01\", \"m/murraja01\", \"w/wiggian01\", \"g/greenra01\", \"v/vucicni01\",\n",
    "    \"m/mobleev01\", \"s/smithja02\", \"b/barnesc01\", \"b/banchpa01\", \"s/suggsca01\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NBA game log scraper for 50 players...\n",
      "\n",
      "Scraping data for player 1/50: j/jamesle01\n",
      "Sending request to Basketball Reference for player j/jamesle01...\n",
      "Request failed with status code: 429\n",
      "Failed to scrape data for j/jamesle01\n",
      "Waiting 29 seconds before next player...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 252\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping failed for all players.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 252\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 226\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m             wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m \u001b[38;5;241m+\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwait_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds before next player...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 226\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Combine all player data into a single DataFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_game_logs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "def scrape_player_game_logs(player_id, season=\"2025\"):\n",
    "    \"\"\"\n",
    "    Scrapes a player's NBA season game logs from Basketball Reference.\n",
    "    \n",
    "    Args:\n",
    "        player_id (str): Player ID from Basketball Reference (e.g., 'jamesle01' or 'j/jamesle01')\n",
    "        season (str): Season year (e.g., '2024' for 2023-2024 season)\n",
    "    \"\"\"\n",
    "    # Check if player_id already contains the first letter path\n",
    "    if '/' in player_id:\n",
    "        # Player ID already includes the letter path (e.g., 'j/jamesle01')\n",
    "        url = f\"https://www.basketball-reference.com/players/{player_id}/gamelog/{season}\"\n",
    "    else:\n",
    "        # Player ID is just the ID part (e.g., 'jamesle01')\n",
    "        url = f\"https://www.basketball-reference.com/players/{player_id[0]}/{player_id}/gamelog/{season}\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    print(f\"Sending request to Basketball Reference for player {player_id}...\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Request successful! Status code: {response.status_code}\")\n",
    "            html_io = StringIO(response.text)\n",
    "            print(\"Parsing tables with pandas...\")\n",
    "            try:\n",
    "                tables = pd.read_html(html_io, attrs={'id': 'pgl_basic'})\n",
    "                if tables and len(tables) > 0:\n",
    "                    print(\"Found game log table by ID!\")\n",
    "                    game_log_df = tables[0]\n",
    "                    processed_df = process_dataframe(game_log_df)\n",
    "                    processed_df['player_id'] = player_id  # Add player_id column\n",
    "                    return processed_df\n",
    "            except Exception as e:\n",
    "                print(f\"Couldn't find table by ID: {e}\")\n",
    "                html_io.seek(0)\n",
    "                tables = pd.read_html(html_io)\n",
    "                tables_sorted = sorted(tables, key=lambda x: len(x), reverse=True)\n",
    "                if tables_sorted:\n",
    "                    game_log_df = tables_sorted[0]\n",
    "                    print(f\"Table found! Dimensions: {game_log_df.shape}\")\n",
    "                    processed_df = process_dataframe(game_log_df)\n",
    "                    processed_df['player_id'] = player_id  # Add player_id column\n",
    "                    return processed_df\n",
    "                else:\n",
    "                    print(\"No tables found on the page.\")\n",
    "                    return None\n",
    "        else:\n",
    "            print(f\"Request failed with status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_dataframe(game_log_df):\n",
    "    \"\"\"\n",
    "    Process the raw dataframe from Basketball Reference to clean and format it properly.\n",
    "    \"\"\"\n",
    "    print(\"Processing the game log dataframe...\")\n",
    "    # Print the first few rows to help with debugging\n",
    "    print(\"First few rows of raw data:\")\n",
    "    print(game_log_df.head(3))\n",
    "    \n",
    "    if isinstance(game_log_df.columns, pd.MultiIndex):\n",
    "        # Handle multi-level columns\n",
    "        game_log_df.columns = [' '.join(str(col) for col in cols if str(col) != 'Unnamed: 0_level_0').strip() \n",
    "                             for cols in game_log_df.columns.values]\n",
    "    \n",
    "    print(\"Raw columns:\", game_log_df.columns.tolist())\n",
    "    \n",
    "    # Remove header rows (where Rk column appears again in the data)\n",
    "    game_log_df = game_log_df[~game_log_df.iloc[:, 0].astype(str).str.contains(\"Rk\")]\n",
    "    \n",
    "    # Remove unnamed columns\n",
    "    unnamed_cols = [col for col in game_log_df.columns if 'Unnamed' in str(col)]\n",
    "    if unnamed_cols:\n",
    "        game_log_df = game_log_df.drop(columns=unnamed_cols)\n",
    "    \n",
    "    # Handle team column naming\n",
    "    if 'Tm' in game_log_df.columns and 'Team' not in game_log_df.columns:\n",
    "        game_log_df = game_log_df.rename(columns={'Tm': 'Team'})\n",
    "    elif 'Tm' in game_log_df.columns and 'Team' in game_log_df.columns and game_log_df['Team'].isna().all():\n",
    "        game_log_df['Team'] = game_log_df['Tm']\n",
    "        game_log_df = game_log_df.drop(columns=['Tm'])\n",
    "    \n",
    "    # Fill missing team values\n",
    "    if 'Team' in game_log_df.columns and game_log_df['Team'].isna().any():\n",
    "        game_log_df['Team'] = game_log_df['Team'].fillna('Unknown')\n",
    "    elif 'Team' not in game_log_df.columns and 'Tm' not in game_log_df.columns:\n",
    "        game_log_df['Team'] = 'Unknown'\n",
    "    \n",
    "    # Check for and handle the MP (Minutes Played) column\n",
    "    if 'MP' in game_log_df.columns:\n",
    "        \n",
    "        game_log_df['MP'] = game_log_df['MP'].apply(lambda x: convert_minutes_format(x) if pd.notna(x) else x)\n",
    "    elif 'MIN' in game_log_df.columns:\n",
    "        game_log_df = game_log_df.rename(columns={'MIN': 'MP'})\n",
    "        game_log_df['MP'] = game_log_df['MP'].apply(lambda x: convert_minutes_format(x) if pd.notna(x) else x)\n",
    "    \n",
    "    # Convert all possible numeric columns\n",
    "    for col in game_log_df.columns:\n",
    "        if col not in ['Date', 'Tm', 'Team', 'Opp', 'Result', 'GS', 'player_id']:\n",
    "            game_log_df[col] = pd.to_numeric(game_log_df[col], errors='coerce')\n",
    "    \n",
    "    # Additional check for MP column\n",
    "    if 'MP' not in game_log_df.columns:\n",
    "        print(\"MP column not found in the data. Available columns:\", game_log_df.columns.tolist())\n",
    "        game_log_df['MP'] = None  # Create the column with None values if it doesn't exist\n",
    "        \n",
    "        \n",
    "        minute_column_variants = ['Minutes', 'Min', 'Mins', 'Minutes Played']\n",
    "        for col_name in minute_column_variants:\n",
    "            if col_name in game_log_df.columns:\n",
    "                game_log_df['MP'] = game_log_df[col_name]\n",
    "                game_log_df['MP'] = game_log_df['MP'].apply(lambda x: convert_minutes_format(x) if pd.notna(x) else x)\n",
    "                print(f\"Found minutes data in column: {col_name}\")\n",
    "                break\n",
    "    \n",
    "    expected_columns = ['Date', 'Team', 'Opp', 'Result', 'MP']\n",
    "    missing_cols = [col for col in expected_columns if col not in game_log_df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing expected columns: {missing_cols}\")\n",
    "    \n",
    "    return game_log_df\n",
    "\n",
    "def convert_minutes_format(minutes_str):\n",
    "    \"\"\"\n",
    "    Convert minutes from 'MM:SS' string format to decimal minutes.\n",
    "    Example: '36:12' becomes 36.2 (36 minutes and 12 seconds)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(minutes_str, (int, float)):\n",
    "            return float(minutes_str)\n",
    "        elif isinstance(minutes_str, str):\n",
    "            if ':' in minutes_str:\n",
    "                parts = minutes_str.split(':')\n",
    "                if len(parts) == 2:\n",
    "                    minutes = int(parts[0])\n",
    "                    seconds = int(parts[1])\n",
    "                    return minutes + seconds/60\n",
    "            else:\n",
    "                return float(minutes_str)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting minutes format: {e}, value was: {minutes_str}\")\n",
    "        return None\n",
    "\n",
    "def save_to_csv(df, filename='nba_player_game_logs.csv'):\n",
    "    \"\"\"\n",
    "    Saves the DataFrame to a CSV file.\n",
    "    \"\"\"\n",
    "    if df is not None:\n",
    "        try:\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Data saved to {filename}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving CSV: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the scraping workflow for multiple players.\n",
    "    \"\"\"\n",
    "    # List of player IDs to scrape\n",
    "    player_ids = [\n",
    "        \"j/jamesle01\", \"c/curryst01\", \"d/duranke01\", \"a/antetgi01\", \"d/doncilu01\", \n",
    "        \"j/jokicni01\", \"e/embiijo01\", \"t/tatumja01\", \"b/butleji01\", \"l/leonaka01\", \n",
    "        \"l/lillada01\", \"h/hardeja01\", \"d/davisan02\", \"b/bookede01\", \"m/mitchdo01\", \n",
    "        \"w/willizi01\", \"m/moranja01\", \"y/youngtr01\", \"t/townska01\", \"b/bealbr01\", \n",
    "        \"g/georgpa01\", \"i/irvinky01\", \"p/paulch01\", \"d/derozde01\", \"w/westbru01\", \n",
    "        \"a/adebaba01\", \"h/holidjr01\", \"m/middlkh01\", \"s/siakapa01\", \"v/vanvlfr01\", \n",
    "        \"g/gilgesh01\", \"i/ingrabr01\", \"m/mccolcj01\", \"b/ballla01\", \"h/halibty01\", \n",
    "        \"r/randlju01\", \"b/barrerj01\", \"f/foxde01\", \"s/sabondo01\", \"t/turnemy01\", \n",
    "        \"p/portemi01\", \"m/murraja01\", \"w/wiggian01\", \"g/greenra01\", \"v/vucicni01\", \n",
    "        \"m/mobleev01\", \"s/smithja02\", \"b/barnesc01\", \"b/banchpa01\", \"s/suggsca01\"\n",
    "    ]\n",
    "    \n",
    "    season = \"2025\"  \n",
    "    \n",
    "    print(f\"Starting NBA game log scraper for {len(player_ids)} players...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    all_game_logs = []\n",
    "    \n",
    "    \n",
    "    checkpoint_interval = 5  # Save after every 5 players\n",
    "    \n",
    "    for i, player_id in enumerate(player_ids):\n",
    "        print(f\"\\nScraping data for player {i+1}/{len(player_ids)}: {player_id}\")\n",
    "        player_game_logs = scrape_player_game_logs(player_id, season)\n",
    "        \n",
    "        if player_game_logs is not None:\n",
    "            all_game_logs.append(player_game_logs)\n",
    "            print(f\"Successfully scraped {len(player_game_logs)} games for {player_id}\")\n",
    "            \n",
    "            # Save checkpoint after every few players\n",
    "            if (i + 1) % checkpoint_interval == 0 and all_game_logs:\n",
    "                checkpoint_df = pd.concat(all_game_logs, ignore_index=True)\n",
    "                checkpoint_filename = f\"checkpoint_nba_logs_{i+1}_players.csv\"\n",
    "                save_to_csv(checkpoint_df, checkpoint_filename)\n",
    "                print(f\"Checkpoint saved to {checkpoint_filename} after {i+1} players\")\n",
    "            \n",
    "            # Add a significant delay between players to avoid rate limiting\n",
    "            if i < len(player_ids) - 1:  \n",
    "                wait_time = 10 + random.randint(5, 15)  \n",
    "                print(f\"Waiting {wait_time} seconds before next player to avoid rate limiting...\")\n",
    "                time.sleep(wait_time)\n",
    "        else:\n",
    "            print(f\"Failed to scrape data for {player_id}\")\n",
    "            \n",
    "            if i < len(player_ids) - 1:\n",
    "                wait_time = 15 + random.randint(5, 15)\n",
    "                print(f\"Waiting {wait_time} seconds before next player...\")\n",
    "                time.sleep(wait_time)\n",
    "    \n",
    "    # Combine all player data into a single DataFrame\n",
    "    if all_game_logs:\n",
    "        combined_df = pd.concat(all_game_logs, ignore_index=True)\n",
    "        print(f\"\\nCombined dataset created with {len(combined_df)} total game logs\")\n",
    "        \n",
    "        # Save combined data\n",
    "        save_to_csv(combined_df, f\"nba_game_logs_{season}.csv\")\n",
    "        \n",
    "        # Print sample and statistics\n",
    "        print(\"\\nSample of the scraped data:\")\n",
    "        print(combined_df.head())\n",
    "        \n",
    "        print(\"\\nBasic statistics:\")\n",
    "        print(f\"Total games: {len(combined_df)}\")\n",
    "        print(f\"Players included: {combined_df['player_id'].nunique()}\")\n",
    "        print(\"\\nAvailable columns:\")\n",
    "        print(combined_df.columns.tolist())\n",
    "        \n",
    "        # Save intermediate results after every 10 players\n",
    "        print(\"\\nTotal time elapsed:\", time.time() - start_time)\n",
    "    else:\n",
    "        print(\"Scraping failed for all players.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_existing_data(filename='nba_game_logs_2025.csv'):\n",
    "    \"\"\"\n",
    "    Load existing dataset if available, return empty DataFrame if file doesn't exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            df = pd.read_csv(filename)\n",
    "            print(f\"Loaded existing dataset with {len(df)} records from {filename}\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"File {filename} not found. Will create a new dataset.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing data: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_additional_players(new_player_ids, existing_filename='nba_game_logs_2025.csv', season=\"2025\"):\n",
    "    \"\"\"\n",
    "    Scrapes game logs for new players and combines with existing data.\n",
    "    \"\"\"\n",
    "    # Load existing data\n",
    "    existing_df = load_existing_data(existing_filename)\n",
    "    \n",
    "    # Get list of players already in the dataset to avoid duplicates\n",
    "    existing_players = set()\n",
    "    if existing_df is not None and 'player_id' in existing_df.columns:\n",
    "        existing_players = set(existing_df['player_id'].unique())\n",
    "        print(f\"Existing dataset contains {len(existing_players)} players\")\n",
    "    \n",
    "    # Filter out players that are already in the dataset\n",
    "    players_to_scrape = [p_id for p_id in new_player_ids if p_id not in existing_players]\n",
    "    \n",
    "    if not players_to_scrape:\n",
    "        print(\"All players in the new list are already in the dataset. Nothing to scrape.\")\n",
    "        return existing_df\n",
    "    \n",
    "    print(f\"Scraping data for {len(players_to_scrape)} new players...\")\n",
    "    \n",
    "    # Scrape the new players\n",
    "    start_time = time.time()\n",
    "    new_game_logs = []\n",
    "    checkpoint_interval = 5\n",
    "    \n",
    "    for i, player_id in enumerate(players_to_scrape):\n",
    "        print(f\"\\nScraping data for new player {i+1}/{len(players_to_scrape)}: {player_id}\")\n",
    "        player_game_logs = scrape_player_game_logs(player_id, season)\n",
    "        \n",
    "        if player_game_logs is not None:\n",
    "            new_game_logs.append(player_game_logs)\n",
    "            print(f\"Successfully scraped {len(player_game_logs)} games for {player_id}\")\n",
    "            \n",
    "            # Save checkpoint after every few players\n",
    "            if (i + 1) % checkpoint_interval == 0 and new_game_logs:\n",
    "                checkpoint_df = pd.concat(new_game_logs, ignore_index=True)\n",
    "                checkpoint_filename = f\"new_checkpoint_nba_logs_{i+1}_players.csv\"\n",
    "                save_to_csv(checkpoint_df, checkpoint_filename)\n",
    "                print(f\"Checkpoint saved to {checkpoint_filename} after {i+1} new players\")\n",
    "            \n",
    "            # No waiting time between players\n",
    "            print(\"Continuing to next player immediately...\")\n",
    "        else:\n",
    "            print(f\"Failed to scrape data for {player_id}\")\n",
    "            \n",
    "            if i < len(players_to_scrape) - 1:\n",
    "                print(\"Continuing to next player...\")\n",
    "    \n",
    "    # Combine all new player data\n",
    "    if new_game_logs:\n",
    "        new_combined_df = pd.concat(new_game_logs, ignore_index=True)\n",
    "        print(f\"\\nNew dataset created with {len(new_combined_df)} total game logs\")\n",
    "        \n",
    "        # Merge with existing data if it exists\n",
    "        if existing_df is not None:\n",
    "            # Combine new data with existing data\n",
    "            final_df = pd.concat([existing_df, new_combined_df], ignore_index=True)\n",
    "            print(f\"Combined dataset now has {len(final_df)} total game logs from {final_df['player_id'].nunique()} players\")\n",
    "        else:\n",
    "            final_df = new_combined_df\n",
    "            print(f\"No existing data to merge. New dataset has {len(final_df)} game logs\")\n",
    "        \n",
    "        # Save combined data\n",
    "        save_to_csv(final_df, existing_filename)\n",
    "        \n",
    "        # Print sample and statistics\n",
    "        print(\"\\nSample of the updated dataset:\")\n",
    "        print(final_df.head())\n",
    "        \n",
    "        print(\"\\nBasic statistics:\")\n",
    "        print(f\"Total games: {len(final_df)}\")\n",
    "        print(f\"Players included: {final_df['player_id'].nunique()}\")\n",
    "        print(\"Total scraping time:\", time.time() - start_time)\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"Scraping failed for all new players.\")\n",
    "        return existing_df\n",
    "\n",
    "def main_additional():\n",
    "    \"\"\"\n",
    "    Main function to add new players to the existing dataset.\n",
    "    \"\"\"\n",
    "    # Specify the new list of player IDs to scrape\n",
    "    new_player_ids = [\n",
    "        # Add your new list of player IDs here\n",
    "        \"e/edwaran01\", \"g/giddesh01\", \"h/hendeco01\", \"m/maxeyty01\", \"m/murraja01\", \n",
    "        \"h/holmgri01\", \"b/brogdma01\", \"a/aytonde01\", \"j/johnsja05\", \"r/reeveau01\",\n",
    "        \"b/brownja02\", \"b/banchpa01\", \"w/wagnefr01\", \"s/sengaal01\", \"t/thomptr01\",\n",
    "        \"p/porzikr01\", \"m/murrays01\", \"b/brunjan01\", \"h/hartjo01\", \"a/aldrila01\",\n",
    "        \"r/russeda01\", \"h/hayesjk01\", \"w/washinpj01\", \"c/claxcni01\", \"d/davisan03\",\n",
    "        \"g/gainesd01\", \"m/millspa01\", \"l/lowryky01\", \"w/whitede01\", \"c/claxtca01\",\n",
    "        \"g/goberru01\", \"a/allenja01\", \"p/poweljn01\", \"b/brissoo01\", \"p/poeleja01\"\n",
    "    ]\n",
    "    \n",
    "    existing_filename = \"nba_game_logs_2025.csv\"  # The name of your existing dataset\n",
    "    season = \"2025\"\n",
    "    \n",
    "    # Run the scraping and data aggregation\n",
    "    final_dataset = scrape_additional_players(new_player_ids, existing_filename, season)\n",
    "    \n",
    "    if final_dataset is not None:\n",
    "        print(\"\\nData aggregation complete! Updated dataset is saved to\", existing_filename)\n",
    "    else:\n",
    "        print(\"\\nFailed to update the dataset.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use main_additional() instead of main() to scrape additional players\n",
    "    main_additional()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Gcar</th>\n",
       "      <th>Gtm</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Result</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>...</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>GmSc</th>\n",
       "      <th>+/-</th>\n",
       "      <th>player_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>LAL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>W, 110-103</td>\n",
       "      <td>*</td>\n",
       "      <td>34.650000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>j/jamesle01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-10-25</td>\n",
       "      <td>LAL</td>\n",
       "      <td>PHO</td>\n",
       "      <td>W, 123-116</td>\n",
       "      <td>*</td>\n",
       "      <td>34.700000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>j/jamesle01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-10-26</td>\n",
       "      <td>LAL</td>\n",
       "      <td>SAC</td>\n",
       "      <td>W, 131-127</td>\n",
       "      <td>*</td>\n",
       "      <td>33.766667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>j/jamesle01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>LAL</td>\n",
       "      <td>PHO</td>\n",
       "      <td>L, 105-109</td>\n",
       "      <td>*</td>\n",
       "      <td>35.800000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>j/jamesle01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>LAL</td>\n",
       "      <td>CLE</td>\n",
       "      <td>L, 110-134</td>\n",
       "      <td>*</td>\n",
       "      <td>28.966667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>j/jamesle01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>72.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2025-04-06</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IND</td>\n",
       "      <td>L, 120-125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.583333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>w/westbru01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>73.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SAC</td>\n",
       "      <td>W, 124-116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>w/westbru01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>W, 117-109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.866667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>w/westbru01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>DEN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>W, 126-111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.633333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>w/westbru01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43-32</td>\n",
       "      <td>36</td>\n",
       "      <td>2094.000000</td>\n",
       "      <td>373.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>w/westbru01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rk    Gcar   Gtm        Date     Team  Opp      Result   GS  \\\n",
       "0      1.0  1493.0   1.0  2024-10-22      LAL  MIN  W, 110-103    *   \n",
       "1      2.0  1494.0   2.0  2024-10-25      LAL  PHO  W, 123-116    *   \n",
       "2      3.0  1495.0   3.0  2024-10-26      LAL  SAC  W, 131-127    *   \n",
       "3      4.0  1496.0   4.0  2024-10-28      LAL  PHO  L, 105-109    *   \n",
       "4      5.0  1497.0   5.0  2024-10-30      LAL  CLE  L, 110-134    *   \n",
       "...    ...     ...   ...         ...      ...  ...         ...  ...   \n",
       "2068  72.0  1234.0  79.0  2025-04-06      DEN  IND  L, 120-125  NaN   \n",
       "2069  73.0  1235.0  80.0  2025-04-09      DEN  SAC  W, 124-116  NaN   \n",
       "2070  74.0  1236.0  81.0  2025-04-11      DEN  MEM  W, 117-109  NaN   \n",
       "2071  75.0  1237.0  82.0  2025-04-13      DEN  HOU  W, 126-111  NaN   \n",
       "2072   NaN     NaN   NaN         NaN  Unknown  NaN       43-32   36   \n",
       "\n",
       "               MP     FG  ...    TRB    AST    STL   BLK    TOV     PF    PTS  \\\n",
       "0       34.650000    7.0  ...    5.0    4.0    0.0   2.0    2.0    3.0   16.0   \n",
       "1       34.700000    7.0  ...    4.0    8.0    0.0   0.0    2.0    1.0   21.0   \n",
       "2       33.766667   12.0  ...   14.0   10.0    0.0   1.0    5.0    3.0   32.0   \n",
       "3       35.800000    3.0  ...    5.0    8.0    1.0   0.0    2.0    1.0   11.0   \n",
       "4       28.966667    9.0  ...    6.0    3.0    0.0   0.0    6.0    2.0   26.0   \n",
       "...           ...    ...  ...    ...    ...    ...   ...    ...    ...    ...   \n",
       "2068    23.583333    6.0  ...    5.0    4.0    0.0   0.0    1.0    4.0   16.0   \n",
       "2069    16.750000    2.0  ...    4.0    4.0    1.0   0.0    3.0    2.0    5.0   \n",
       "2070    26.866667    4.0  ...    3.0    4.0    2.0   0.0    2.0    0.0   14.0   \n",
       "2071    22.633333    5.0  ...    0.0    6.0    0.0   0.0    1.0    1.0   17.0   \n",
       "2072  2094.000000  373.0  ...  370.0  457.0  106.0  37.0  242.0  188.0  994.0   \n",
       "\n",
       "      GmSc   +/-    player_id  \n",
       "0     10.1  -6.0  j/jamesle01  \n",
       "1     17.9  14.0  j/jamesle01  \n",
       "2     27.1  13.0  j/jamesle01  \n",
       "3      6.9 -17.0  j/jamesle01  \n",
       "4     18.0 -17.0  j/jamesle01  \n",
       "...    ...   ...          ...  \n",
       "2068  12.7 -14.0  w/westbru01  \n",
       "2069   0.1  -4.0  w/westbru01  \n",
       "2070  13.0  11.0  w/westbru01  \n",
       "2071  15.1   8.0  w/westbru01  \n",
       "2072  10.9 -24.0  w/westbru01  \n",
       "\n",
       "[2073 rows x 34 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"nba_game_logs_2025.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
